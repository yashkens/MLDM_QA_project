{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba0df205-94de-4b2c-b6b8-1360440a2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13134f2a-ecc9-4a0f-9309-c0260fa02e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35d9087c-dc43-4d6a-9e01-62b10e030508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a22a6ea3-f8c6-4787-b835-b02589553e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'v1.0-simplified_nq-dev-all.jsonl'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "data = []\n",
    "for json_str in json_list:\n",
    "    data.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd32790-1f21-49db-87b1-5c980c47cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nq_tokens(simplified_nq_example):\n",
    "\n",
    "    if \"document_text\" not in simplified_nq_example:\n",
    "        raise ValueError(\"`get_nq_tokens` should be called on a simplified NQ\"\n",
    "                     \"example that contains the `document_text` field.\")\n",
    "\n",
    "    return simplified_nq_example[\"document_text\"].split(\" \")\n",
    "\n",
    "\n",
    "def simplify_nq_example(nq_example):\n",
    "\n",
    "    def _clean_token(token):\n",
    "        return re.sub(u\" \", \"_\", token[\"token\"])\n",
    "\n",
    "    text = \" \".join([_clean_token(t) for t in nq_example[\"document_tokens\"]])\n",
    "\n",
    "    def _remove_html_byte_offsets(span):\n",
    "        if \"start_byte\" in span:\n",
    "            del span[\"start_byte\"]\n",
    "\n",
    "        if \"end_byte\" in span:\n",
    "            del span[\"end_byte\"]\n",
    "\n",
    "        return span\n",
    "\n",
    "    def _clean_annotation(annotation):\n",
    "        annotation[\"long_answer\"] = _remove_html_byte_offsets(\n",
    "            annotation[\"long_answer\"])\n",
    "        annotation[\"short_answers\"] = [\n",
    "            _remove_html_byte_offsets(sa) for sa in annotation[\"short_answers\"]\n",
    "        ]\n",
    "        return annotation\n",
    "\n",
    "    simplified_nq_example = {\n",
    "      \"question_text\": nq_example[\"question_text\"],\n",
    "      \"example_id\": nq_example[\"example_id\"],\n",
    "      \"document_url\": nq_example[\"document_url\"],\n",
    "      \"document_text\": text,\n",
    "      \"long_answer_candidates\": [\n",
    "          _remove_html_byte_offsets(c)\n",
    "          for c in nq_example[\"long_answer_candidates\"]\n",
    "      ],\n",
    "      \"annotations\": [_clean_annotation(a) for a in nq_example[\"annotations\"]]\n",
    "    }\n",
    "\n",
    "    if len(get_nq_tokens(simplified_nq_example)) != len(\n",
    "      nq_example[\"document_tokens\"]):\n",
    "        raise ValueError(\"Incorrect number of tokens.\")\n",
    "\n",
    "    return simplified_nq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2fc72a5-a446-407e-8765-805885ac299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 15\n",
    "KAGGLE_FORMAT = False\n",
    "\n",
    "def get_question_and_document(line):\n",
    "    question = line['question_text']\n",
    "    text = line['document_text'].split(' ')\n",
    "    annotations = line['annotations'][0]\n",
    "    \n",
    "    return question, text, annotations\n",
    "\n",
    "\n",
    "def get_long_candidate(i, annotations, candidate):\n",
    "    if i == annotations['long_answer']['candidate_index']:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "\n",
    "    # get place where long answer starts and ends in the document text\n",
    "    long_start = candidate['start_token']\n",
    "    long_end = candidate['end_token']\n",
    "    \n",
    "    return label, long_start, long_end\n",
    "\n",
    "\n",
    "def form_data_row(question, label, text, long_start, long_end):\n",
    "    row = {\n",
    "        'question': question,\n",
    "        'long_answer': ' '.join(text[long_start:long_end]),\n",
    "        'is_long_answer': label,\n",
    "    }\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    rows = []\n",
    "\n",
    "    for line in data:\n",
    "        if not KAGGLE_FORMAT:\n",
    "            line = simplify_nq_example(line)\n",
    "        question, text, annotations = get_question_and_document(line)\n",
    "        for i, candidate in enumerate(line['long_answer_candidates']):\n",
    "            label, long_start, long_end = get_long_candidate(i, annotations, candidate)\n",
    "\n",
    "            if label == True or (i % SAMPLE_RATE == 0):\n",
    "                rows.append(\n",
    "                    form_data_row(question, label, text, long_start, long_end)\n",
    "                )\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86aa3c19-7ac6-4bec-8401-06c796be08ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do the 3 dots mean in math</td>\n",
       "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; ∴ &lt;/Th&gt; &lt;/Tr&gt; &lt;T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what do the 3 dots mean in math</td>\n",
       "      <td>&lt;Tr&gt; &lt;Td&gt; hyphen &lt;/Td&gt; &lt;Td&gt; ‐ &lt;/Td&gt; &lt;/Tr&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do the 3 dots mean in math</td>\n",
       "      <td>&lt;Tr&gt; &lt;Td&gt; asterisk &lt;/Td&gt; &lt;Td&gt; * &lt;/Td&gt; &lt;/Tr&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what do the 3 dots mean in math</td>\n",
       "      <td>&lt;Tr&gt; &lt;Td&gt; ordinal indicator &lt;/Td&gt; &lt;Td&gt; o a &lt;/T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what do the 3 dots mean in math</td>\n",
       "      <td>&lt;Tr&gt; &lt;Td&gt; sound - recording copyright &lt;/Td&gt; &lt;T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          question  \\\n",
       "0  what do the 3 dots mean in math   \n",
       "1  what do the 3 dots mean in math   \n",
       "2  what do the 3 dots mean in math   \n",
       "3  what do the 3 dots mean in math   \n",
       "4  what do the 3 dots mean in math   \n",
       "\n",
       "                                         long_answer  is_long_answer  \n",
       "0  <Table> <Tr> <Th_colspan=\"2\"> ∴ </Th> </Tr> <T...               0  \n",
       "1          <Tr> <Td> hyphen </Td> <Td> ‐ </Td> </Tr>               0  \n",
       "2        <Tr> <Td> asterisk </Td> <Td> * </Td> </Tr>               0  \n",
       "3  <Tr> <Td> ordinal indicator </Td> <Td> o a </T...               0  \n",
       "4  <Tr> <Td> sound - recording copyright </Td> <T...               0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3d6a2fe-647c-4762-a58e-1e2cda16b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    words = sentence.split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_html(sentence):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', sentence)\n",
    "\n",
    "def clean_df_by_column(df, column):\n",
    "    df[column] = df[column].apply(lambda x : remove_stopwords(x))\n",
    "    df[column] = df[column].apply(lambda x : remove_html(x))\n",
    "    return df\n",
    "\n",
    "def clean_df(df):\n",
    "    df = clean_df_by_column(df, 'long_answer')\n",
    "    df = clean_df_by_column(df, 'question')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7af1de6b-ee7f-4e8f-a518-b61749c1d549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30037</th>\n",
       "      <td>channel abc phoenix arizona</td>\n",
       "      <td>This list broadcast television stations servi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69029</th>\n",
       "      <td>sang cold outside tom jones</td>\n",
       "      <td>Catatonia formed 1992 . She subsequently sang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26220</th>\n",
       "      <td>list celebrities hollywood star</td>\n",
       "      <td>Tim McCoy   Motion pictures   1600 Vine Stre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44150</th>\n",
       "      <td>head parliament uk</td>\n",
       "      <td>Where Government lost confidence House Common...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62902</th>\n",
       "      <td>last time michigan basketball championship</td>\n",
       "      <td>2014 -- Nik Stauskas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "30037                 channel abc phoenix arizona   \n",
       "69029                 sang cold outside tom jones   \n",
       "26220             list celebrities hollywood star   \n",
       "44150                          head parliament uk   \n",
       "62902  last time michigan basketball championship   \n",
       "\n",
       "                                             long_answer  is_long_answer  \n",
       "30037   This list broadcast television stations servi...               0  \n",
       "69029   Catatonia formed 1992 . She subsequently sang...               1  \n",
       "26220    Tim McCoy   Motion pictures   1600 Vine Stre...               0  \n",
       "44150   Where Government lost confidence House Common...               0  \n",
       "62902                              2014 -- Nik Stauskas                0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = clean_df(data)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e975f657-5ff5-464e-b0c5-6d6cb80a1b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question          3771\n",
       "long_answer       3771\n",
       "is_long_answer    3771\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_long_answer == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9048978c-87cf-4e2e-ba6b-5ba65ea1e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a04763e-8169-4247-a0cc-72f94fb7fef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 dots mean math'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data.loc[0].question\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f5ac6b-140f-4f50-a692-1acdcc67f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1017, 14981, 2812, 8785, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "['3', 'dots', 'mean', 'math']\n",
      "[1017, 14981, 2812, 8785]\n",
      "3 dots mean math\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(example))\n",
    "tokens = tokenizer.tokenize(example)\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "213ef571-f94d-4f53-af04-9bf104379768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "65bf240a-cafa-4bec-a1aa-384a7fa3dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAnswerDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=150):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "        self._questions = data.question.values\n",
    "        self._long_answers = data.long_answer.values\n",
    "        self._targets = data.is_long_answer.values\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_tokens = self._questions[idx].split()\n",
    "        input_tokens.append(' ' + self._tokenizer.sep_token + ' ')\n",
    "        long_answer_tokens = self._long_answers[idx].split()\n",
    "        input_tokens.extend(long_answer_tokens)\n",
    "        encoding = self._tokenizer(input_tokens,\n",
    "                          is_split_into_words=True,\n",
    "                          return_offsets_mapping=True,\n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          max_length=self._max_len,\n",
    "                          return_tensors='pt')\n",
    "        encoding.pop('token_type_ids')\n",
    "        encoding.pop('offset_mapping')\n",
    "        encoding.pop('attention_mask')\n",
    "        return encoding, self._targets[idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72906519-71f9-4e88-afa4-25f5d4c263fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71656, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "481be6a6-cb34-444a-9c56-7599c4171778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids'])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lad = LongAnswerDataset(test_df, tokenizer)\n",
    "lad[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5373ebd3-ebda-4ae5-a1fc-d52aa4c2c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example, target = lad[10]\n",
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ee13e2e8-ea39-45a4-8a0a-3c87e1fc6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(lad, batch_size=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b2bd4960-5b5f-4a66-b215-c06084a0c943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 150]), torch.Size([1, 150]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['input_ids'].shape, example['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "549fe6a5-622d-4350-bab0-2e2556d118ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c4e83693-99b4-4764-9f36-f35ba37b822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LongAnswerDataset(data[:60000], tokenizer)\n",
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "dataset = LongAnswerDataset(data[60000:], tokenizer)\n",
    "val_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3061cdeb-f0e5-48c7-a47f-8ea37104ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAnswerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden1, hidden2):\n",
    "        super(LongAnswerClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2003f058-6052-4932-b37d-879bdf11c0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongAnswerClassifier(\n",
       "  (fc1): Linear(in_features=150, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LongAnswerClassifier(dataset._max_len, 128, 64)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "69b731f4-d150-4f45-8429-6da258c1ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fb69a0ab-c723-463f-8ea2-e06959b41430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\tTrain Loss: 36.251\n",
      "Epoch #2\tTrain Loss: 46.888\n",
      "Epoch #3\tTrain Loss: 29.829\n",
      "Epoch #4\tTrain Loss: 18.933\n",
      "Epoch #5\tTrain Loss: 15.849\n",
      "Epoch #6\tTrain Loss: 6.891\n",
      "Epoch #7\tTrain Loss: 4.301\n",
      "Epoch #8\tTrain Loss: 2.132\n",
      "Epoch #9\tTrain Loss: 2.454\n",
      "Epoch #10\tTrain Loss: 1.378\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_losses = []\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    total = 0\n",
    "    for inputs, target in train_loader:\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(inputs['input_ids'])\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        \n",
    "        loss.backward()\n",
    "              \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "    \n",
    "    epoch_loss = sum(losses) / total\n",
    "    train_losses.append(epoch_loss)\n",
    "        \n",
    "    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ee4f76a7-daf4-47f9-acc1-24e54a71a0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        inputs, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(inputs['input_ids'])\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        predicted = torch.sigmoid(outputs)\n",
    "        predicted = predicted.apply_(lambda x: 1 if x >= 0.5 else 0).squeeze(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print(predicted)\n",
    "        # print(labels)\n",
    "print(f'Accuracy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937d23a-56fe-4fbc-a6bb-ae2c664fc1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
