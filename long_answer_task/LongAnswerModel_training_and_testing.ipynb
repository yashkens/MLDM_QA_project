{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844338c4-bce1-4fef-be1e-afd349dcfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3571a5c-c23a-4601-8dcf-0f595d7d7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../notebooks/v1.0-simplified_nq-dev-all.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "data = []\n",
    "for json_str in json_list:\n",
    "    data.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf749c3-9cde-46ac-a0c9-5c7e3701d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095f56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nq_tokens(simplified_nq_example):\n",
    "\n",
    "    if \"document_text\" not in simplified_nq_example:\n",
    "        raise ValueError(\"`get_nq_tokens` should be called on a simplified NQ\"\n",
    "                         \"example that contains the `document_text` field.\")\n",
    "\n",
    "    return simplified_nq_example[\"document_text\"].split(\" \")\n",
    "\n",
    "\n",
    "# this func is taken from official NaturalQuestions repo too\n",
    "def simplify_nq_example(nq_example):\n",
    "\n",
    "    def _clean_token(token):\n",
    "        return re.sub(u\" \", \"_\", token[\"token\"])\n",
    "\n",
    "    text = \" \".join([_clean_token(t) for t in nq_example[\"document_tokens\"]])\n",
    "\n",
    "    def _remove_html_byte_offsets(span):\n",
    "        if \"start_byte\" in span:\n",
    "            del span[\"start_byte\"]\n",
    "\n",
    "        if \"end_byte\" in span:\n",
    "            del span[\"end_byte\"]\n",
    "\n",
    "        return span\n",
    "\n",
    "    def _clean_annotation(annotation):\n",
    "        annotation[\"long_answer\"] = _remove_html_byte_offsets(\n",
    "            annotation[\"long_answer\"])\n",
    "        annotation[\"short_answers\"] = [\n",
    "            _remove_html_byte_offsets(sa) for sa in annotation[\"short_answers\"]\n",
    "        ]\n",
    "        return annotation\n",
    "\n",
    "    simplified_nq_example = {\n",
    "      \"question_text\": nq_example[\"question_text\"],\n",
    "      \"example_id\": nq_example[\"example_id\"],\n",
    "      \"document_url\": nq_example[\"document_url\"],\n",
    "      \"document_text\": text,\n",
    "      \"long_answer_candidates\": [\n",
    "          _remove_html_byte_offsets(c)\n",
    "          for c in nq_example[\"long_answer_candidates\"]\n",
    "      ],\n",
    "      \"annotations\": [_clean_annotation(a) for a in nq_example[\"annotations\"]]\n",
    "    }\n",
    "\n",
    "    if len(get_nq_tokens(simplified_nq_example)) != len(\n",
    "      nq_example[\"document_tokens\"]):\n",
    "        raise ValueError(\"Incorrect number of tokens.\")\n",
    "\n",
    "    return simplified_nq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c0cf12-856b-48fa-b249-1e8734ecba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee3a131-12ae-4904-957c-0c997d877cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAnswerDatasetBase(Dataset):\n",
    "    SAMPLE_RATE = 15\n",
    "    HTML_PATTERN = re.compile(r'<.*?>')\n",
    "    \n",
    "    def _get_nq_tokens(self, simplified_nq_example):\n",
    "        if \"document_text\" not in simplified_nq_example:\n",
    "            raise ValueError(\"`get_nq_tokens` should be called on a simplified NQ\"\n",
    "                         \"example that contains the `document_text` field.\")\n",
    "\n",
    "        return simplified_nq_example[\"document_text\"].split(\" \")\n",
    "    \n",
    "    def _clean_token(self, token):\n",
    "        return re.sub(u\" \", \"_\", token[\"token\"])\n",
    "\n",
    "    def _remove_html_byte_offsets(self, span):\n",
    "        if \"start_byte\" in span:\n",
    "            del span[\"start_byte\"]\n",
    "\n",
    "        if \"end_byte\" in span:\n",
    "            del span[\"end_byte\"]\n",
    "\n",
    "        return span\n",
    "\n",
    "    def _clean_annotation(self, annotation):\n",
    "        annotation[\"long_answer\"] = self._remove_html_byte_offsets(\n",
    "            annotation[\"long_answer\"])\n",
    "        annotation[\"short_answers\"] = [\n",
    "            self._remove_html_byte_offsets(sa) for sa in annotation[\"short_answers\"]\n",
    "        ]\n",
    "        return annotation\n",
    "    \n",
    "    def _simplify_nq_example(self, nq_example):\n",
    "        text = \" \".join([self._clean_token(t) for t in nq_example[\"document_tokens\"]])\n",
    "\n",
    "        simplified_nq_example = {\n",
    "          \"question_text\": nq_example[\"question_text\"],\n",
    "          \"example_id\": nq_example[\"example_id\"],\n",
    "          \"document_url\": nq_example[\"document_url\"],\n",
    "          \"document_text\": text,\n",
    "          \"long_answer_candidates\": [\n",
    "              self._remove_html_byte_offsets(c)\n",
    "              for c in nq_example[\"long_answer_candidates\"]\n",
    "          ],\n",
    "          \"annotations\": [self._clean_annotation(a) for a in nq_example[\"annotations\"]]\n",
    "        }\n",
    "\n",
    "        if len(self._get_nq_tokens(simplified_nq_example)) != len(\n",
    "          nq_example[\"document_tokens\"]):\n",
    "            raise ValueError(\"Incorrect number of tokens.\")\n",
    "\n",
    "        return simplified_nq_example\n",
    "    \n",
    "    def _get_question_and_document(self, line):\n",
    "        question = line['question_text']\n",
    "        text = line['document_text'].split(' ')\n",
    "        long_answer_candidates = line['long_answer_candidates']\n",
    "        example_id = line['example_id']\n",
    "\n",
    "        return question, text, long_answer_candidates, example_id\n",
    "\n",
    "\n",
    "    def _get_long_candidate(self, i, annotations, candidate):\n",
    "        if i == annotations['long_answer']['candidate_index']:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        # get place where long answer starts and ends in the document text\n",
    "        long_start = candidate['start_token']\n",
    "        long_end = candidate['end_token']\n",
    "\n",
    "        return label, long_start, long_end\n",
    "    \n",
    "    def _preprocess_data(self, data):\n",
    "        rows = []\n",
    "\n",
    "        for line in data:\n",
    "            if not self._kaggle_format:\n",
    "                line = self._simplify_nq_example(line)\n",
    "            question, text, long_answe, example_id = self._get_question_and_document(line)\n",
    "            for i, candidate in enumerate(line['long_answer_candidates']):\n",
    "                label, long_start, long_end = self._get_long_candidate(i, annotations, candidate)\n",
    "\n",
    "                if label == True or (i % self.SAMPLE_RATE == 0):\n",
    "                    rows.append(\n",
    "                        self._form_data_row(question, label, text, long_start, long_end)\n",
    "                    )\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "    \n",
    "    def _remove_stopwords(self, sentence):\n",
    "        words = sentence.split()\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_html(self, sentence):\n",
    "        return  self.HTML_PATTERN.sub(r'', sentence)\n",
    "\n",
    "    def _clean_df_by_column(self, df, column):\n",
    "        # df[column] = df[column].apply(lambda x : self._remove_stopwords(x))\n",
    "        df[column] = df[column].apply(lambda x : self._remove_html(x))\n",
    "        return df\n",
    "\n",
    "    def _clean_df(self, df):\n",
    "        df = self._clean_df_by_column(df, 'long_answer')\n",
    "        df = self._clean_df_by_column(df, 'question')\n",
    "        return df\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError('method __getitem__ is not implemented')\n",
    "    \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError('method __len__ is not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1285e1-d2d7-406a-b560-7d2c9952f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2ad05c-9bdd-4ec7-a09a-acf137c2c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLongAnswerDataset(LongAnswerDatasetBase):\n",
    "    def __init__(self, data, tokenizer, max_len=150, kaggle_format=True, balance=True):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "        self._kaggle_format = kaggle_format\n",
    "        \n",
    "        data = self._preprocess_data(data)\n",
    "        data = self._clean_df(data)\n",
    "        if balance:\n",
    "            data = self._balance_data(data)\n",
    "        self._questions = data.question.values\n",
    "        self._long_answers = data.long_answer.values\n",
    "        self._targets = data.is_long_answer.values\n",
    "        \n",
    "    \n",
    "    def _balance_data(self, data):\n",
    "        data_unbalanced_majority = data[data.is_long_answer == 0]\n",
    "        data_unbalanced_minority = data[data.is_long_answer == 1]\n",
    "        majority_size = data_unbalanced_majority.shape[0]\n",
    "        data_balanced_minority = resample(data_unbalanced_minority, \n",
    "                                          replace=True,\n",
    "                                          n_samples=majority_size)\n",
    "        data_balanced = pd.concat([data_unbalanced_majority, data_balanced_minority])\n",
    "        return shuffle(data_balanced).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    def _form_data_row(self, question, label, text, long_start, long_end):\n",
    "        row = {\n",
    "            'question': question,\n",
    "            'long_answer': ' '.join(text[long_start:long_end]),\n",
    "            'is_long_answer': label,\n",
    "        }\n",
    "\n",
    "        return row\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_tokens = self._questions[idx].split()\n",
    "        input_tokens.append(' ' + self._tokenizer.sep_token + ' ')\n",
    "        long_answer_tokens = self._long_answers[idx].split()\n",
    "        input_tokens.extend(long_answer_tokens)\n",
    "        encoding = self._tokenizer(input_tokens,\n",
    "                          is_split_into_words=True,\n",
    "                          return_offsets_mapping=False,\n",
    "                          return_token_type_ids=False,\n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          max_length=self._max_len,\n",
    "                          return_tensors='pt')\n",
    "        return encoding, self._targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35054671-3584-4a19-986b-fce3d3a96637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLongAnswerDatasetDicreasing(TrainLongAnswerDataset):\n",
    "    def _balance_data(self, data):\n",
    "        data_unbalanced_majority = data[data.is_long_answer == 0]\n",
    "        data_unbalanced_minority = data[data.is_long_answer == 1]\n",
    "        minority_size = data_unbalanced_minority.shape[0]\n",
    "        data_balanced_majority = resample(data_unbalanced_majority, \n",
    "                                          replace=False,\n",
    "                                          n_samples=minority_size * 2)\n",
    "        data_balanced = pd.concat([data_balanced_majority, data_unbalanced_minority])\n",
    "        return shuffle(data_balanced).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b9bdf8-d410-4ef3-94f1-d4627555052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLongAnswerDataset(LongAnswerDatasetBase):\n",
    "    def __init__(self, data, tokenizer, max_len=150, kaggle_format=True):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "        self._kaggle_format = kaggle_format\n",
    "        \n",
    "        data = self._preprocess_data(data)\n",
    "        data = self._clean_df(data)\n",
    "        self._data = {index: question_df for index, (question, question_df) in enumerate(data.groupby('question'))}\n",
    "\n",
    "    def _form_data_row(self, question, label, text, long_start, long_end):\n",
    "        row = {\n",
    "            'question': question,\n",
    "            'long_answer': ' '.join(text[long_start:long_end]),\n",
    "            'is_long_answer': label,\n",
    "            'long_start': long_start,\n",
    "            'long_end': long_end\n",
    "        }\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels, texts, indices = [], [], []\n",
    "        current_data = self._data[idx]\n",
    "        for i in range(current_data.shape[0]):\n",
    "            question = current_data.question.iloc[i]\n",
    "            answer = current_data.long_answer.iloc[i]\n",
    "            start = current_data.long_start.iloc[i]\n",
    "            end = current_data.long_end.iloc[i]\n",
    "            \n",
    "            texts.append(question + self._tokenizer.sep_token + answer)\n",
    "            labels.append(current_data.is_long_answer.iloc[i])\n",
    "            indices.append(f\"{start}:{end}\")\n",
    "            \n",
    "        encoding = self._tokenizer(texts,\n",
    "                                   return_offsets_mapping=False,\n",
    "                                   return_token_type_ids=False,\n",
    "                                   padding='max_length',\n",
    "                                   truncation=True,\n",
    "                                   max_length=self._max_len,\n",
    "                                   return_tensors='pt')\n",
    "        return encoding, labels, indices\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72778785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba920d7f-ddb8-44d0-a36c-1db554cedb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongAnswerModel():\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "#         self.model.to(device)\n",
    "        \n",
    "        # PARALLEL\n",
    "        self.model = DataParallel(self.model).to(device)\n",
    "        \n",
    "    def __call__(self, input_ids, attn_mask):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            input_ids = input_ids.to(self.device)\n",
    "            output = self.model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "            logits = output['logits']\n",
    "            active_logits = logits.view(-1, model.num_labels)\n",
    "            flattened_pred = torch.argmax(active_logits, axis=1)\n",
    "            if 1 in flattened_pred:\n",
    "                ind = torch.argmax(active_logits[:, 1]).item()\n",
    "                prediction = torch.zeros_like(flattened_pred)\n",
    "                prediction[ind] = 1\n",
    "                return prediction\n",
    "        return flattened_pred\n",
    "        \n",
    "        \n",
    "    def plot_log(self, train_losses, train_fscores, val_losses, val_fscores, log_name):\n",
    "        clear_output()\n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(9, 3))\n",
    "        fig.suptitle('Training Log', fontsize=8)\n",
    "        ax1.plot(train_losses)\n",
    "        ax1.set_title('Train Loss', fontsize=8)\n",
    "        ax1.tick_params(labelsize=6)\n",
    "        ax2.plot(train_fscores)\n",
    "        ax2.set_title('Train F1', fontsize=8)\n",
    "        ax2.tick_params(labelsize=6)\n",
    "\n",
    "        ax3.plot(val_losses)\n",
    "        ax3.set_title('Val Loss', fontsize=8)\n",
    "        ax3.tick_params(labelsize=6)\n",
    "        ax4.plot(val_fscores)\n",
    "        ax4.set_title(\"Val F1\", fontsize=8)\n",
    "        ax4.tick_params(labelsize=6)\n",
    "        plt.savefig(f'log_{log_name}.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def validate(self, val_dataloader):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        val_loss, val_fscore = 0, 0\n",
    "        \n",
    "        # ADDED TORCH NO GRAD\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "\n",
    "                tokens, labels = batch\n",
    "                ids = tokens['input_ids'].to(self.device).squeeze(dim=1)\n",
    "                mask = tokens['attention_mask'].to(self.device).squeeze(dim=1)\n",
    "                labels = labels.to(self.device) #.squeeze(dim=1)\n",
    "\n",
    "                output = self.model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "                loss = output['loss']\n",
    "                logits = output['logits']\n",
    "\n",
    "                # PARALLEL\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                        loss = loss.mean()\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                gold = labels.view(-1)\n",
    "                active_logits = logits.view(-1, model.num_labels)\n",
    "                pred = torch.argmax(active_logits, axis=1) \n",
    "\n",
    "                fscore = f1_score(gold.cpu().numpy(), pred.cpu().numpy(), average='micro')\n",
    "                val_fscore += fscore\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        avg_val_f1 = val_fscore / len(val_dataloader)\n",
    "        return avg_val_loss, avg_val_f1\n",
    "    \n",
    "    def train(self, train_dataloader, val_dataloader, n_epoch, optimizer, checkpoint_step, model_save_name):\n",
    "        \n",
    "        train_losses, val_losses = [], []\n",
    "        train_fscores, val_fscores = [], []\n",
    "                \n",
    "        for epoch in range(n_epoch):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            self.model.train()\n",
    "            \n",
    "            train_loss, train_fscore = 0, 0\n",
    "            step_train_losses, step_train_fscores, step_val_losses, step_val_fscores = [], [], [], []\n",
    "            for step_num, batch in enumerate(train_dataloader):\n",
    "                \n",
    "                tokens, labels = batch\n",
    "                ids = tokens['input_ids'].to(self.device).squeeze(dim=1)\n",
    "                mask = tokens['attention_mask'].to(self.device).squeeze(dim=1)\n",
    "                labels = labels.to(self.device) # .squeeze(dim=1)\n",
    "                \n",
    "                output = self.model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "                loss = output['loss']\n",
    "                logits = output['logits']\n",
    "            \n",
    "                # PARALLEL\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                        loss = loss.mean()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # compute accuracy\n",
    "                gold = labels.view(-1)\n",
    "                active_logits = logits.view(-1, model.num_labels)\n",
    "                pred = torch.argmax(active_logits, axis=1) \n",
    "\n",
    "                fscore = f1_score(gold.cpu().numpy(), pred.cpu().numpy(), average='micro')\n",
    "                train_fscore += fscore\n",
    "                \n",
    "                if step_num % 200 == 0:\n",
    "                    print(f\"Step №{step_num}!\")\n",
    "                    \n",
    "                \n",
    "                if step_num % checkpoint_step == 0:\n",
    "                    step_train_losses.append(train_loss / (step_num + 1))\n",
    "                    step_train_fscores.append(train_fscore / (step_num + 1))\n",
    "                    print(f\"Step №{step_num}\")\n",
    "                    print(\"Running validation...\")\n",
    "                    val_loss_tmp, val_f1_tmp = self.validate(val_dataloader)\n",
    "                    if len(step_val_fscores) > 0 and step_val_fscores[-1] < val_f1_tmp:\n",
    "                        torch.save(self.model.state_dict(), model_save_name)\n",
    "                    step_val_losses.append(val_loss_tmp)\n",
    "                    step_val_fscores.append(val_f1_tmp)\n",
    "                    self.plot_log(step_train_losses, step_train_fscores,\n",
    "                                  step_val_losses, step_val_fscores, f\"{epoch}_{step_num}\")\n",
    "                    print(f\"Train loss: {step_train_losses[-1]:.4f}\")\n",
    "                    print(f\"Train F-score: {step_train_fscores[-1]:.4f}\")\n",
    "                    print(f\"Val loss: {val_loss_tmp:.4f}\")\n",
    "                    print(f\"Val F-score: {val_f1_tmp:.4f}\")\n",
    "                \n",
    "            avg_train_loss = train_loss / len(train_dataloader)\n",
    "            avg_train_f1 = train_fscore / len(train_dataloader)\n",
    "            \n",
    "            avg_val_loss, avg_val_f1 = self.validate(val_dataloader)\n",
    "            \n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_fscores.append(avg_val_f1)\n",
    "            \n",
    "            self.plot_log(train_losses, train_fscores, val_losses, val_fscores, f\"EPOCH_{epoch}\")\n",
    "            \n",
    "            print(f'Epoch {epoch}')\n",
    "            print(f'Train loss: {avg_train_loss:.3f}')\n",
    "            print(f'Train micro F1: {avg_train_f1:.3f}')\n",
    "            print(f'Validation loss: {avg_val_loss:.3f}')\n",
    "            print(f'Validation micro F1: {avg_val_f1:.3f}')\n",
    "            curr_time = time.time() - start_time\n",
    "            print(f'Epoch time: {curr_time:.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b89fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03abfc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52814783-f43c-4236-aafa-f7e46c4ac599",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "dataset1 = TrainLongAnswerDatasetDicreasing(train, tokenizer, max_len, kaggle_format=False)\n",
    "train_dataloader = DataLoader(dataset1, batch_size=5, shuffle=True)\n",
    "\n",
    "dataset2 = TrainLongAnswerDatasetDicreasing(val, tokenizer, max_len, kaggle_format=False)\n",
    "val_dataloader = DataLoader(dataset2, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd42fb3-a0ba-4834-a6ad-11440f7e6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = TestLongAnswerDataset(test, tokenizer, max_len, kaggle_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea812fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(val_dataloader), len(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55209cf4-de28-4ece-a69b-730d62cc41b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "305e7660-28da-4ed0-b9a0-12309807d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-05\n",
    "lr = 1e-06\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7d2eed-6ec8-4b44-b137-89eff6f152d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict = torch.load('long_answer_model_freeze_balance_small.pt', map_location=device)\n",
    "# new_state_dict = {}\n",
    "# for key, value in state_dict.items():\n",
    "#     new_state_dict[key.replace('module.', '')] = value\n",
    "# model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b96fd71-de97-4d32-9ec1-1a27e5c701f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_model = LongAnswerModel(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc38edb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bc7b086-f3be-4666-9d64-e357ee7e82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train loss: 0.563\n",
      "Train micro F1: 0.783\n",
      "Validation loss: 0.552\n",
      "Validation micro F1: 0.754\n",
      "Epoch time: 4269.969s\n"
     ]
    }
   ],
   "source": [
    "answer_model.train(train_dataloader, val_dataloader, 1, optimizer, 50, 'long_answer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3e438",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67379059-fc3d-4bbf-aec1-00df775d46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eddf4f3-b21f-4eb6-b1bd-a84a4ab11ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inds(labels, indices):\n",
    "    if 1 not in labels:\n",
    "        return '-1:-1'\n",
    "    ind = labels.index(1)\n",
    "    return indices[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db3fa8-be01-4233-b8b6-4e3c7770d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, gold = [], []\n",
    "\n",
    "for batch in dataset3:\n",
    "    encoding, labels, indices = batch\n",
    "    answer = answer_model(encoding['input_ids'], encoding['attention_mask'])\n",
    "    print(get_inds(answer.cpu().tolist(), indices), get_inds(labels, indices))\n",
    "    pred.append(get_inds(answer.cpu().tolist(), indices))\n",
    "    gold.append(get_inds(labels, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9e1e8a6-4aa8-4843-9fde-b0573a61104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 0.5842\n"
     ]
    }
   ],
   "source": [
    "print(f\"F score: {f1_score(pred, gold, average='micro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7eecb7-1cfd-4a0c-b227-f9472a9e18a1",
   "metadata": {},
   "source": [
    "### How to balance data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e725b-2df5-47db-9e3e-9bca08b05155",
   "metadata": {},
   "source": [
    "[resample](https://elitedatascience.com/imbalanced-classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1166f95-c682-40dd-b4cf-9bd5b79adf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16cfccb0-f396-4d7b-9649-722f800d9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unbalanced = dataset2.data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da128aa7-0c7d-4bc0-a7ad-fdbc48210539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who becomes chief resident on grey's anatomy s...</td>\n",
       "      <td>April Kepner     Grey 's Anatomy character ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who becomes chief resident on grey's anatomy s...</td>\n",
       "      <td>Religion   Christianity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who becomes chief resident on grey's anatomy s...</td>\n",
       "      <td>Kepner reveals that she is a virgin because s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who becomes chief resident on grey's anatomy s...</td>\n",
       "      <td>In Season 12 , April and Jackson go through d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list of environmentally critical areas in the ...</td>\n",
       "      <td>This is a list of protected areas of the Phil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  who becomes chief resident on grey's anatomy s...   \n",
       "1  who becomes chief resident on grey's anatomy s...   \n",
       "2  who becomes chief resident on grey's anatomy s...   \n",
       "3  who becomes chief resident on grey's anatomy s...   \n",
       "4  list of environmentally critical areas in the ...   \n",
       "\n",
       "                                         long_answer  is_long_answer  \n",
       "0     April Kepner     Grey 's Anatomy character ...               0  \n",
       "1                          Religion   Christianity                 0  \n",
       "2   Kepner reveals that she is a virgin because s...               1  \n",
       "3   In Season 12 , April and Jackson go through d...               0  \n",
       "4   This is a list of protected areas of the Phil...               0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unbalanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e7637fd-dd38-4357-8eed-564a2098539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unbalanced_majority = data_unbalanced[data_unbalanced.is_long_answer == 0]\n",
    "data_unbalanced_minority = data_unbalanced[data_unbalanced.is_long_answer == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc883e83-ac0e-4ba7-8b4b-d8e96f1fd6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unbalanced_majority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03aed29d-81ac-42bc-bd96-8250feec248b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unbalanced_minority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b51224c3-df1b-457c-aa68-1f0b1a3dde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced_minority = resample(data_unbalanced_minority, \n",
    "                                  replace=True,\n",
    "                                  n_samples=10200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "282b2a37-c40d-4485-b5e4-15e0c2e42084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10200"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_minority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9bf73ca3-4556-4850-be70-1ae734508164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>played daughters last man standing</td>\n",
       "      <td>Tim Allen Mike Baxter : Mike father three da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>played detective little boy blue</td>\n",
       "      <td>Stephen Graham -- Detective Superintendent Da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>non controlling interest balance sheet</td>\n",
       "      <td>In accounting , minority interest ( non-contr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>great wall china built defend</td>\n",
       "      <td>The history Great Wall China began fortificat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>plays little girl jurassic park</td>\n",
       "      <td>Ariana Clarice Richards ( born September 11 ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "7015       played daughters last man standing   \n",
       "567          played detective little boy blue   \n",
       "10398  non controlling interest balance sheet   \n",
       "3161            great wall china built defend   \n",
       "4007          plays little girl jurassic park   \n",
       "\n",
       "                                             long_answer  is_long_answer  \n",
       "7015     Tim Allen Mike Baxter : Mike father three da...               1  \n",
       "567     Stephen Graham -- Detective Superintendent Da...               1  \n",
       "10398   In accounting , minority interest ( non-contr...               1  \n",
       "3161    The history Great Wall China began fortificat...               1  \n",
       "4007    Ariana Clarice Richards ( born September 11 ,...               1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_minority.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "919689e7-ba31-456a-a201-0c8a47ef7701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_minority.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d854a0ac-1aff-4840-aa5d-d12c66d47231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = pd.concat([data_unbalanced_majority, data_balanced_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "778060f2-91e5-4a98-b2b5-3100493df18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a21c132b-411e-4b8a-825c-9936aa0cc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = shuffle(data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b6a8af7b-0167-49f1-9282-f5d900439275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>justin bieber's purpose song</td>\n",
       "      <td>Australia ( ARIA )   3 × Platinum   210,000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>non controlling interest balance sheet</td>\n",
       "      <td>Some investors expressed concern minority int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>season 2 attack titan many episodes</td>\n",
       "      <td>Season   Episodes   Originally aired     Fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>summer monkeys take place</td>\n",
       "      <td>The book set end nineteenth century . The pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>attack pearl harbor take place</td>\n",
       "      <td>Attack Pearl Harbor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "759              justin bieber's purpose song   \n",
       "10399  non controlling interest balance sheet   \n",
       "4279      season 2 attack titan many episodes   \n",
       "2783                summer monkeys take place   \n",
       "9230           attack pearl harbor take place   \n",
       "\n",
       "                                             long_answer  is_long_answer  \n",
       "759        Australia ( ARIA )   3 × Platinum   210,000                 0  \n",
       "10399   Some investors expressed concern minority int...               0  \n",
       "4279      Season   Episodes   Originally aired     Fi...               1  \n",
       "2783    The book set end nineteenth century . The pro...               1  \n",
       "9230                                Attack Pearl Harbor                0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf3b22a5-15fc-485b-8043-1fef3885e60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>is_long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>justin bieber's purpose song</td>\n",
       "      <td>Australia ( ARIA )   3 × Platinum   210,000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non controlling interest balance sheet</td>\n",
       "      <td>Some investors expressed concern minority int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>season 2 attack titan many episodes</td>\n",
       "      <td>Season   Episodes   Originally aired     Fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summer monkeys take place</td>\n",
       "      <td>The book set end nineteenth century . The pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attack pearl harbor take place</td>\n",
       "      <td>Attack Pearl Harbor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question  \\\n",
       "0            justin bieber's purpose song   \n",
       "1  non controlling interest balance sheet   \n",
       "2     season 2 attack titan many episodes   \n",
       "3               summer monkeys take place   \n",
       "4          attack pearl harbor take place   \n",
       "\n",
       "                                         long_answer  is_long_answer  \n",
       "0      Australia ( ARIA )   3 × Platinum   210,000                 0  \n",
       "1   Some investors expressed concern minority int...               0  \n",
       "2     Season   Episodes   Originally aired     Fi...               1  \n",
       "3   The book set end nineteenth century . The pro...               1  \n",
       "4                               Attack Pearl Harbor                0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced.reset_index(drop=True).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
